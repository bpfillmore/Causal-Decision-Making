
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Overview &#8212; Causal Decision Making</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=888ff710"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=36754332"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_old files(to delete)/Map';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../Intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Causal Decision Making - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Causal Decision Making - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../Intro.html">
                    Introduction
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Overview</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../Overview.html">Overview</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Motivating Examples</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../0_Motivating_Examples/CSL.html">Causal Structure Learning (CSL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_Motivating_Examples/CEL.html">Causal Effect Learning (CEL)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../0_Motivating_Examples/CPL.html">Causal Policy Learning (CPL)</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Preliminary</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../1_Preliminary/Causal%20Inference%20Preliminary.html">Causal Inference Preliminary</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Structure Learning (CSL)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../2_Causal_Structure_Learning/Preliminaries%20of%20Causal%20Graphs.html">Preliminaries of Causal Graphs</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../2_Causal_Structure_Learning/Causal%20Discovery.html">Causal Discovery</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../2_Causal_Structure_Learning/Testing-based%20Learner.html">Testing-based Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2_Causal_Structure_Learning/Functional-based%20Learner.html">Functional-based Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../2_Causal_Structure_Learning/Score-based%20Learner.html">Score-based Learner</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../2_Causal_Structure_Learning/Causal%20Mediation%20Analysis.html">Causal Mediation Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Effect Learning (CEL)</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/Single%20Stage.html"><strong>Single Stage – Paradigm 1</strong></a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/ATE.html">ATE Estimation</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/HTE.html">HTE Estimation</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/S-learner.html"><strong>1. S-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/T-learner.html"><strong>2. T-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/X-learner.html"><strong>3. X-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/R-Learner.html"><strong>4. R learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/DR-Learner.html"><strong>5. DR-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/Lp-R-Learner.html"><strong>6. Lp-R-learner</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/GRF.html"><strong>7. Generalized Random Forest</strong></a></li>


<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/Dragonnet.html"><strong>8. Dragon Net</strong></a></li>


</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%201/Mediation%20Analysis.html">Mediation Analysis</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%202/underMDP.html">Markov Decision Processes – Paradigm 2</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%203/Panel%20Data.html">Panel Data  – Paradigm 3</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%203/DiD.html"><strong>Difference in Difference</strong></a></li>

<li class="toctree-l2"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%203/Synthetic%20Control.html"><strong>Synthetic Control</strong></a></li>




<li class="toctree-l2 has-children"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%203/Extensions.html">Extensions</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%203/Matrix%20Completion.html"><strong>Matrix Completion</strong></a></li>

<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%203/Synthetic%20DiD.html"><strong>Synthetic DiD</strong></a></li>

<li class="toctree-l3"><a class="reference internal" href="../3_Causal_Effect_Learning/Scenario%203/H1SL_H2SL.html"><strong>H1SL and H2SL</strong></a></li>

</ul>
</li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 1</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Single%20Stage.html">Single Stage</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Discrete.html">Discrete Action Space</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Q-learning_Single.html">Q-Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/A-learning_Single.html">A-Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Classification/O-Learning.html">Outcome Weighted Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Quantile/QuantileOTR_test.html">Quantile Optimal Treatment Regime</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Continuous.html">Continuous Action Space</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Continuous/Deep%20Jump%20Learner.html">Deep Jump Learner for Continuous Actions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Continuous/Kernel-Based%20Learner.html">Kernel-Based Learner</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Continuous/Outcome%20Learning.html">Outcome Learning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/PlanToDo.html">Plan To Do</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario1/Classification/E-learning.html">Entropy learning</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 2</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/preliminary_MDP-potential-outcome.html">Preliminary: Off-policy Evaluation and Optimization in Markov Decision Processes</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/Evaluation.html">Policy Evaluation–Value Estimation</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/FQE.html">Fitted-Q Evaluation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/IPW_Infinite.html">Importance Sampling for Policy Evaluation (Infinite Horizon)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/DR_Infinite.html">Doubly Robust Estimator for Policy Evaluation (Infinite Horizon)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/Deeply_Debiased.html">Deeply-Debiased Off-Policy Evaluation</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/MediationRL.html">Policy Evaluation--Mediation Analysis</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/Optimization.html">Policy Optimization</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario2/FQI.html">Fitted-Q Iteration</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 3</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario3/Multi%20Stage.html">Multiple Stages (DTR)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario3/Q-learning_Multiple.html">Q-Learning</a></li>
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario3/A-learning_Multiple.html">A-Learning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 4</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Bandits.html">Overview: Bandits ALgorithm</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/MAB/MAB.html">Multi-Armed Bandits (MAB)</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/MAB/Epsilon_Greedy.html"><span class="math notranslate nohighlight">\(\epsilon\)</span>-Greedy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/MAB/UCB.html">UCB</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/MAB/TS.html">TS</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/Contextual_Bandits.html">Contextual Bandits</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinUCB.html">LinUCB</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Contextual_Bandits/LinTS.html">LinTS</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_Bandits.html">Meta Bandits</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Meta_Bandits/Meta_TS.html">Meta Thompson Sampling</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Meta_Bandits/MTTS.html">Multi-Task Thompson Sampling (MTTS)</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Structured_Bandit.html">Structured Bandit (Slate Recommendation)</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/Learning%20to%20rank.html">Online Learning to Rank (Cascading Bandit)</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/TS_Cascade.html">TS_Cascade</a></li>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/CascadeLinTS.html">CascadeLinTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Cascade/MTSS_Cascade.html">MTSS_Cascade</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/Combinatorial%20Optimization.html">Online Combinatorial Optimization (Combinatorial Semi-Bandit)</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombTS.html">CombTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/CombLinTS.html">CombLinTS</a></li>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/Combinatorial-Semi/MTSS_Comb.html">MTSS_Comb</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/Assortment%20Optimization.html">Dynamic Assortment Optimization (Multinomial Logit Bandit)</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_MNL_Beta.html">TS_MNL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/TS_Contextual_MNL.html">TS_Contextual_MNL</a></li>
<li class="toctree-l3"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/Structured_Bandits/MNL/MTSS_MNL.html">MTSS_MNL</a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/OnlineEval/Online%20Policy%20Evaluation.html">Online Policy Evaluation</a><input class="toctree-checkbox" id="toctree-checkbox-18" name="toctree-checkbox-18" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-18"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/OnlineEval/Direct%20Online%20Policy%20Evaluator.html">Direct Online Policy Evaluator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/OnlineEval/Inverse%20Probability%20Weighted%20Online%20Policy%20Evaluator.html">Inverse Probability Weighted Online Policy Evaluator</a></li>
<li class="toctree-l2"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario4/OnlineEval/Doubly%20Robust%20Online%20Policy%20Evaluator.html">Doubly Robust Online Policy Evaluator</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 5</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario5/OnlineRL_Markov.html">Online Policy Learning and Evaluation in Markovian Environments</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Causal Policy Learning (CPL)--Paradigm 6</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../4_Causal_Policy_Learning/Scenario6/OnlineRL_non_Markov.html">Ooline Policy Learning in Non-Markovian Environments</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Case Studies</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../5_Case_Study/MIMIC3/MIMIC3_intro.html">Mimic3</a><input class="toctree-checkbox" id="toctree-checkbox-19" name="toctree-checkbox-19" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-19"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../5_Case_Study/MIMIC3/MIMIC3-Demo-Ver2.html">Mimic3 Demo-Ver2</a></li>


<li class="toctree-l2"><a class="reference internal" href="../5_Case_Study/MIMIC3/Single_Stage.html">MIMIC III (Single-Stage)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../5_Case_Study/MIMIC3/Longitudinal.html">MIMIC III (3-Stages)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../5_Case_Study/MIMIC3/Infinite_Horizon.html">MIMIC III (Infinite Horizon)</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../5_Case_Study/MovieLens/MovieLens.html">MovieLens</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/CausalDM/Causal-Decision-Making/tree/main" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/CausalDM/Causal-Decision-Making/tree/main/issues/new?title=Issue%20on%20page%20%2F_old files(to delete)/Map.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/_old files(to delete)/Map.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Overview</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-expect">What to expect?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#causal-structure-learning-csl"><a name="SL"></a> Causal Structure Learning (CSL)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#causal-effect-learning-cel"><a name="ML"></a> Causal Effect Learning (CEL)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#causal-policy-learning-cpl"><a name="PL"></a> Causal Policy Learning (CPL)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-1-i-i-d"><a name="Case1"></a> Scenario 1: I.I.D</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-2-offline-reinforcement-learning"><a name="Case2"></a> Scenario 2: Offline Reinforcement Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-3-multiple-stage-dtr"><a name="Case3"></a> Scenario 3: Multiple-Stage DTR</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-4-adaptive-decision-making-with-independent-states-admis"><a name="Case4"></a> Scenario 4: Adaptive Decision Making with Independent States (ADMIS)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-5-online-reinforcement-learning"><a name="Case5"></a> Scenario 5: Online Reinforcement Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-6-all-others"><a name="Case6"></a> Scenario 6: All others</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-scenario-1"><a name="SingelDTR"></a> A. Scenario 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-scenario-2"><a name="MDP"></a> B. Scenario 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-scenario-3"><a name="MultiDTR"></a> C. Scenario 3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-scenario-4"><a name="Bandits"></a> D. Scenario 4</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reference">Reference</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h1>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Link to this heading">#</a></h2>
</section>
<hr class="docutils" />
<section id="what-to-expect">
<h2>What to expect?<a class="headerlink" href="#what-to-expect" title="Link to this heading">#</a></h2>
<hr class="docutils" />
<p>The diagram below depicts the overall structure of this book, which is comprised of three primary components: <strong>Causal Structure Learning</strong>, <strong>Causal Policy Learning</strong>, and <strong>Causal Effect Learning</strong>. Specifically, in the chapter <a class="reference internal" href="#SL"><span class="xref myst"><strong>Causal Structure Learning (CSL)</strong></span></a>, we present state-of-the-art techniques for learning the skeleton of causal relationships among input variables. When a causal structure is known, the second chapter of <a class="reference internal" href="#ML"><span class="xref myst"><strong>Causal Effect Learning (CEL)</strong></span></a> introduces approaches making causal inference. Finally, the <a class="reference internal" href="#PL"><span class="xref myst"><strong>Causal Policy Learning (CPL)</strong></span></a> chapter introduces diverse policy learners to learn optimal policies and evaluate various policies of interest.</p>
<p><img alt="Overall.png" src="../_images/Overall.png" /></p>
<p>Following is a brief summary of the contents of each chapter.</p>
</section>
<section id="causal-structure-learning-csl">
<h2><a name="SL"></a> Causal Structure Learning (CSL)<a class="headerlink" href="#causal-structure-learning-csl" title="Link to this heading">#</a></h2>
<hr class="docutils" />
<p>This chapter discusses three classical techniques for learning causal graphs, each with its own merits and downsides.</p>
<table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Learners      Type</p></th>
<th class="head"><p>Supported Model</p></th>
<th class="head"><p>Noise Required for Training</p></th>
<th class="head"><p>Complexity</p></th>
<th class="head"><p>Scale-Free?</p></th>
<th class="head"><p>Learners Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Testing based</p></td>
<td><p>Models 1</p></td>
<td><p>Gaussian</p></td>
<td><p><span class="math notranslate nohighlight">\(O(p^q)\)</span></p></td>
<td><p>Yes</p></td>
<td><p>PC</p></td>
</tr>
<tr class="row-odd"><td><p>Functional based</p></td>
<td><p>Models 1 &amp; 2</p></td>
<td><p>non-Gaussian</p></td>
<td><p><span class="math notranslate nohighlight">\(O(p^3)\)</span></p></td>
<td><p>Yes</p></td>
<td><p>LiNGAM</p></td>
</tr>
<tr class="row-even"><td><p>Score based</p></td>
<td><p>Models 1 &amp; 3</p></td>
<td><p>Gaussian/non-Gaussian</p></td>
<td><p><span class="math notranslate nohighlight">\(O(p^3)\)</span></p></td>
<td><p>No</p></td>
<td><p>NOTEARS</p></td>
</tr>
</tbody>
</table>
<p><em><span class="math notranslate nohighlight">\(p\)</span> is the number of nodes in <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>, and <span class="math notranslate nohighlight">\(q\)</span> is the max number of nodes adjacent to any nodes in <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>.</em></p>
</section>
<section id="causal-effect-learning-cel">
<h2><a name="ML"></a> Causal Effect Learning (CEL)<a class="headerlink" href="#causal-effect-learning-cel" title="Link to this heading">#</a></h2>
</section>
<hr class="docutils" />
<section id="causal-policy-learning-cpl">
<h2><a name="PL"></a> Causal Policy Learning (CPL)<a class="headerlink" href="#causal-policy-learning-cpl" title="Link to this heading">#</a></h2>
<hr class="docutils" />
<p>This chapter focuses on six common data dependence structures in decision making, including <a class="reference internal" href="#Case1"><span class="xref myst"><strong>I.I.D.</strong></span></a>, <a class="reference internal" href="#Case2"><span class="xref myst"><strong>Offline Reinforcement Learning</strong></span></a>, <a class="reference internal" href="#Case3"><span class="xref myst"><strong>Multiple-Stage DTR</strong></span></a>, <a class="reference internal" href="#Case4"><span class="xref myst"><strong>Adaptive Decision Making with Independent States (ADMIS)</strong></span></a>, <a class="reference internal" href="#Case5"><span class="xref myst"><strong>Online Reinforcement Learning</strong></span></a>, and <a class="reference internal" href="#Case6"><span class="xref myst"><strong>All Others</strong></span></a>. The similarities and differences between four scenarios are summarized as follows.</p>
<p><img alt="Causal_DM_Causal_Structure_Table.png" src="../_images/Causal_DM_Causal_Structure_Table.png" /></p>
<section id="scenario-1-i-i-d">
<h3><a name="Case1"></a> Scenario 1: I.I.D<a class="headerlink" href="#scenario-1-i-i-d" title="Link to this heading">#</a></h3>
<p>As the figure illustrated, observations in Scenario 1 are i.i.d. sampled. For each observation, there are three components, <span class="math notranslate nohighlight">\(S_i\)</span> is the context information if there is any, <span class="math notranslate nohighlight">\(A_i\)</span> is the action taken, and <span class="math notranslate nohighlight">\(R_i\)</span> is the reward received. When there is contextual information, the action would be affected by the contextual information, while the final reward would be affected by both the contextual information and the action. A classical class of problems that are widely studied in this context is the <strong>Single-Stage Dynamic Treatment Regime (DTR)</strong>[1]. In this book, we mainly focus on methods for policy evaluation and policy optimization for Single-Stage DTR, with a detailed map in <a class="reference internal" href="#SingleDTR"><span class="xref myst">Appendix A</span></a></p>
</section>
<section id="scenario-2-offline-reinforcement-learning">
<h3><a name="Case2"></a> Scenario 2: Offline Reinforcement Learning<a class="headerlink" href="#scenario-2-offline-reinforcement-learning" title="Link to this heading">#</a></h3>
<p>The Scenario 2 is well-known as Markov Decision Process (MDP), whose main characteristic is the Markovian state transition. In particular, while <span class="math notranslate nohighlight">\(A_t\)</span> is only affected by <span class="math notranslate nohighlight">\(S_t\)</span>, both <span class="math notranslate nohighlight">\(R_t\)</span> and <span class="math notranslate nohighlight">\(S_{t+1}\)</span> would be affected by <span class="math notranslate nohighlight">\((S_t,A_t)\)</span>. Given <span class="math notranslate nohighlight">\(S_{t}, A_t\)</span>, a standard assumption of MDP problems is that <span class="math notranslate nohighlight">\(R_t\)</span> and <span class="math notranslate nohighlight">\(S_{t+1}\)</span> are independent of previous observations. A list of related learning methods will be introduced, with a map in <a class="reference internal" href="#MDP"><span class="xref myst">Appendix B</span></a>.</p>
</section>
<section id="scenario-3-multiple-stage-dtr">
<h3><a name="Case3"></a> Scenario 3: Multiple-Stage DTR<a class="headerlink" href="#scenario-3-multiple-stage-dtr" title="Link to this heading">#</a></h3>
<p>When a history-independent policy is applied, the Scenario 3 takes all the possible causal relationships into account and is well-known as the multiple-stage DTR problem [1]. In this book, we introduce two classical learning methods, including Q-learning and A-learning (See a map in <a class="reference internal" href="#MultiDTR"><span class="xref myst">Appendix C</span></a>)</p>
</section>
<section id="scenario-4-adaptive-decision-making-with-independent-states-admis">
<h3><a name="Case4"></a> Scenario 4: Adaptive Decision Making with Independent States (ADMIS)<a class="headerlink" href="#scenario-4-adaptive-decision-making-with-independent-states-admis" title="Link to this heading">#</a></h3>
<p>The Scenario 4 setting is widely examined in the online decision making literature, especially the bandits, where the treatment policy is time-adaptive. Specifically, <span class="math notranslate nohighlight">\(H_{t-1}\)</span> includes all the previous observations up to time <span class="math notranslate nohighlight">\(t-1\)</span> (include observations at time <span class="math notranslate nohighlight">\(t-1\)</span>) and is used to update the action policy at time <span class="math notranslate nohighlight">\(t\)</span>, and therefore affect the action <span class="math notranslate nohighlight">\(A_t\)</span>. While <span class="math notranslate nohighlight">\(S_t\)</span> is i.i.d sampled from the correponding distribution, <span class="math notranslate nohighlight">\(R_t\)</span> is influenced by both <span class="math notranslate nohighlight">\(A_t\)</span> and <span class="math notranslate nohighlight">\(S_t\)</span>. Finally, the new observation <span class="math notranslate nohighlight">\((S_t,A_t,R_t)\)</span>, in conjunction with all previous observations, would then be formulated as <span class="math notranslate nohighlight">\(H_{t+1}\)</span> and affect <span class="math notranslate nohighlight">\(A_{t+1}\)</span> only. A structure that lacks contextual information <span class="math notranslate nohighlight">\(S_t\)</span> is also very common. In this book, a list of bandits algorithms would be introduced, with a detailed map in <a class="reference internal" href="#Bandits"><span class="xref myst">Appendix D</span></a>.</p>
</section>
<section id="scenario-5-online-reinforcement-learning">
<h3><a name="Case5"></a> Scenario 5: Online Reinforcement Learning<a class="headerlink" href="#scenario-5-online-reinforcement-learning" title="Link to this heading">#</a></h3>
<p>Building upon the MDP structure, when an adaptive policy is applied, the Scenario 5 clearly depicts the data-generating process, in which  <span class="math notranslate nohighlight">\(S_t\)</span> follows the Markovian state transition and <span class="math notranslate nohighlight">\(A_t\)</span> would be affected by all previous observations <span class="math notranslate nohighlight">\(H_{t-1}\)</span>.</p>
</section>
<section id="scenario-6-all-others">
<h3><a name="Case6"></a> Scenario 6: All others<a class="headerlink" href="#scenario-6-all-others" title="Link to this heading">#</a></h3>
</section>
</section>
<section id="appendix">
<h2>Appendix<a class="headerlink" href="#appendix" title="Link to this heading">#</a></h2>
<hr class="docutils" />
<section id="a-scenario-1">
<h3><a name="SingelDTR"></a> A. Scenario 1<a class="headerlink" href="#a-scenario-1" title="Link to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Algorithm</p></th>
<th class="head text-center"><p>Treatment Type</p></th>
<th class="head text-center"><p>Outcome Type</p></th>
<th class="head text-center"><p>Single Stage?</p></th>
<th class="head text-center"><p>Multiple Stages?</p></th>
<th class="head text-center"><p>Infinite Horizon?</p></th>
<th class="head text-center"><p>Evaluation?</p></th>
<th class="head text-center"><p>Optimization?</p></th>
<th class="head text-center"><p>C.I.?</p></th>
<th class="head text-center"><p>Advantages</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://www.jmlr.org/papers/volume6/murphy05a/murphy05a.pdf">Q-Learning</a></p></td>
<td class="text-center"><p>Discrete</p></td>
<td class="text-center"><p>Continuous (Mean)</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference external" href="https://www.researchgate.net/profile/Eric-Laber/publication/221665211_Q-_and_A-Learning_Methods_for_Estimating_Optimal_Dynamic_Treatment_Regimes/links/58825d074585150dde402268/Q-and-A-Learning-Methods-for-Estimating-Optimal-Dynamic-Treatment-Regimes.pdf">A-Learning</a></p></td>
<td class="text-center"><p>Discrete</p></td>
<td class="text-center"><p>Continuous (Mean)</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://www.tandfonline.com/doi/pdf/10.1080/01621459.2012.695674?casa_token=bwkVvffpyFcAAAAA:hlN58Fbz59blLj5npZFjEQD-HkPeMevEN5pWWLu_vuIVxPWl5aYShgCVHUVeODAfj6Pr8DpzGFlPZ1E">OWL</a></p></td>
<td class="text-center"><p>Discrete</p></td>
<td class="text-center"><p>Continuous (Mean)</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>❗BOWL</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>❗TODO</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference external" href="https://doi.org/10.1080/01621459.2017.1330204">Quatile-OTR</a></p></td>
<td class="text-center"><p>Discrete</p></td>
<td class="text-center"><p>Continuous (Quantiles)</p></td>
<td class="text-center"><p>✅✏️</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>✅✏️</p></td>
<td class="text-center"><p>✅✏️</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2021/file/816b112c6105b3ebd537828a39af4818-Paper.pdf">Deep Jump Learner</a></p></td>
<td class="text-center"><p>Continuous</p></td>
<td class="text-center"><p>Continuous/Discrete</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>Flexible to implement &amp; Fast to Converge</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>Kernel-Based Learner</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Outcome Learning</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
</tbody>
</table>
<div>
<img src="Scenario1.png" align="center" width="500"/>
</div>
</section>
<section id="b-scenario-2">
<h3><a name="MDP"></a> B. Scenario 2<a class="headerlink" href="#b-scenario-2" title="Link to this heading">#</a></h3>
<div>
<img src="Scenario2.png" align="center"  width="400"/>
</div>
</section>
<section id="c-scenario-3">
<h3><a name="MultiDTR"></a> C. Scenario 3<a class="headerlink" href="#c-scenario-3" title="Link to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>Algorithm</p></th>
<th class="head text-center"><p>Treatment Type</p></th>
<th class="head text-center"><p>Outcome Type</p></th>
<th class="head text-center"><p>Evaluation?</p></th>
<th class="head text-center"><p>Optimization?</p></th>
<th class="head text-center"><p>C.I.?</p></th>
<th class="head text-center"><p>Advantages</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://www.jmlr.org/papers/volume6/murphy05a/murphy05a.pdf">Q-Learning</a></p></td>
<td class="text-center"><p>Discrete</p></td>
<td class="text-center"><p>Continuous (Mean)</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference external" href="https://www.researchgate.net/profile/Eric-Laber/publication/221665211_Q-_and_A-Learning_Methods_for_Estimating_Optimal_Dynamic_Treatment_Regimes/links/58825d074585150dde402268/Q-and-A-Learning-Methods-for-Estimating-Optimal-Dynamic-Treatment-Regimes.pdf">A-Learning</a></p></td>
<td class="text-center"><p>Discrete</p></td>
<td class="text-center"><p>Continuous (Mean)</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
</tbody>
</table>
<div>
<img src="Scenario3.png" align="center"  width="300"/>
</div>
</section>
<section id="d-scenario-4">
<h3><a name="Bandits"></a> D. Scenario 4<a class="headerlink" href="#d-scenario-4" title="Link to this heading">#</a></h3>
<table class="table">
<thead>
<tr class="row-odd"><th class="head text-left"><p>algorithm</p></th>
<th class="head text-center"><p>Reward</p></th>
<th class="head text-center"><p>with features?</p></th>
<th class="head text-center"><p>Advantage</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td class="text-left"><p><strong>Multi-Armed Bandits</strong></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference internal" href="#"><span class="xref myst"><span class="math notranslate nohighlight">\(\epsilon\)</span>-greedy</span></a></p></td>
<td class="text-center"><p>Binary/Gaussian</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>Simple</p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://www.ccs.neu.edu/home/vip/teach/DMcourse/5_topicmodel_summ/notes_slides/sampling/TS_Tutorial.pdf">TS</a></p></td>
<td class="text-center"><p>Binary/Guaasian</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference external" href="https://link.springer.com/content/pdf/10.1023/A:1013689704352.pdf">UCB1</a></p></td>
<td class="text-center"><p>Binary/Gaussian</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Contextual Bandits</strong></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>LinTS</p></td>
<td class="text-center"><p><a class="reference external" href="http://proceedings.mlr.press/v108/kveton20a/kveton20a.pdf">GLM</a>/<a class="reference external" href="http://proceedings.mlr.press/v28/agrawal13.pdf">Gaussian</a></p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>LinUCB</p></td>
<td class="text-center"><p><a class="reference external" href="http://proceedings.mlr.press/v70/li17c/li17c.pdf">GLM</a>/<a class="reference external" href="https://dl.acm.org/doi/pdf/10.1145/1772690.1772758?casa_token=CJjeIziLmjEAAAAA:CkRvgHQNqpy10rzcUP5kx31NWJmgSldd6zx8wZxskZYCoCc8v7EDIw3t3Gk1_6mfurqQTqRZ7fVA">Guassian</a></p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><strong>Meta Bandits</strong></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p>Meta-TS</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p>MTSS</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><strong>Structured Bandits</strong></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><em>Learning to Rank</em></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="http://proceedings.mlr.press/v89/cheung19a/cheung19a.pdf">TS-Cascade</a></p></td>
<td class="text-center"><p>Binary</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference external" href="https://arxiv.org/pdf/1603.05359.pdf">CascadeLinTS</a></p></td>
<td class="text-center"><p>Binary</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://arxiv.org/pdf/2202.13227.pdf">MTSS-Cascade</a></p></td>
<td class="text-center"><p>Binary</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>Scalable, Robust, accounts for inter-item heterogeneity</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><em>Combinatorial Optimization</em></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="http://proceedings.mlr.press/v80/wang18a/wang18a.pdf">CombTS</a></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference external" href="http://proceedings.mlr.press/v37/wen15.pdf">CombLinTS</a></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://arxiv.org/pdf/2202.13227.pdf">MTSS-Comb</a></p></td>
<td class="text-center"><p>Continuous</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>Scalable, Robust, accounts for inter-item heterogeneity</p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><em>Assortment Optimization</em></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="http://proceedings.mlr.press/v65/agrawal17a/agrawal17a.pdf">MNL-Thompson-Beta</a></p></td>
<td class="text-center"><p>Binary</p></td>
<td class="text-center"><p></p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-odd"><td class="text-left"><p><a class="reference external" href="https://proceedings.neurips.cc/paper/2019/file/36d7534290610d9b7e9abed244dd2f28-Paper.pdf">TS-Contextual-MNL</a></p></td>
<td class="text-center"><p>Binary</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p></p></td>
</tr>
<tr class="row-even"><td class="text-left"><p><a class="reference external" href="https://arxiv.org/pdf/2202.13227.pdf">MTSS-MNL</a></p></td>
<td class="text-center"><p>Binary</p></td>
<td class="text-center"><p>✅</p></td>
<td class="text-center"><p>Scalable, Robust, accounts for inter-item heterogeneity</p></td>
</tr>
</tbody>
</table>
<img src="Scenario4.png" align="center"  width="900"/>
</section>
</section>
<section id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Link to this heading">#</a></h2>
<p>[1] Tsiatis, A. A., Davidian, M., Holloway, S. T., &amp; Laber, E. B. (2019). Dynamic treatment regimes: Statistical methods for precision medicine. Chapman and Hall/CRC.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./_old files(to delete)"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#what-to-expect">What to expect?</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#causal-structure-learning-csl"><a name="SL"></a> Causal Structure Learning (CSL)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#causal-effect-learning-cel"><a name="ML"></a> Causal Effect Learning (CEL)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#causal-policy-learning-cpl"><a name="PL"></a> Causal Policy Learning (CPL)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-1-i-i-d"><a name="Case1"></a> Scenario 1: I.I.D</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-2-offline-reinforcement-learning"><a name="Case2"></a> Scenario 2: Offline Reinforcement Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-3-multiple-stage-dtr"><a name="Case3"></a> Scenario 3: Multiple-Stage DTR</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-4-adaptive-decision-making-with-independent-states-admis"><a name="Case4"></a> Scenario 4: Adaptive Decision Making with Independent States (ADMIS)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-5-online-reinforcement-learning"><a name="Case5"></a> Scenario 5: Online Reinforcement Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#scenario-6-all-others"><a name="Case6"></a> Scenario 6: All others</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">Appendix</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#a-scenario-1"><a name="SingelDTR"></a> A. Scenario 1</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#b-scenario-2"><a name="MDP"></a> B. Scenario 2</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#c-scenario-3"><a name="MultiDTR"></a> C. Scenario 3</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#d-scenario-4"><a name="Bandits"></a> D. Scenario 4</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reference">Reference</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Causal Decision Making Team
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>